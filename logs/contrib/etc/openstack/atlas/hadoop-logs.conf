#/etc/openstack/atlas/hadoop-logs.conf
## Loadbalancing Logs Hadoop Quartz Service Configuration

#Auth Variables
auth_management_uri = https://my-auth-server/v1.1/
basic_auth_user=username
basic_auth_key=password

# This is where the watch dog will look for new logfiles to be processed.
filesystem_root_dir=/var/log/zxtm/rotated/

# This is for secondary backup. Not being used right now.
rawlogs_backup_dir=/tmp/

# This is where the ordered logs from hadoop will be split into customers logs, before being uploaded to Cloud Files.
rawlogs_cache_dir=/var/log/zxtm/hadoop/cache

# These are input and output directories in remote hadoop. No need to create them locally.
mapreduce_input_prefix=/user/lbaas_dev/input/
mapreduce_output_prefix=/user/lbaas_dev/output/


# Other random parameters
rawlogs_part=part-00000
basemapreduce_log_suffix=_logs

# Cron expression to run the job every given hours.
job.repeat.interval=0 0 0/1 * * ?
job_jar_path=/etc/openstack/atlas/hadoop-logs-jobs.jar
hdfs_job_jar_path=/user/lbaas_dev/hadoop-logs-jobs.jar
hdfs_user_name=hadoop_prod_lbaas
hadoop_xml_file=/etc/openstack/atlas/hadoop-conf.xml
num_reducers=30


